Pathogens & Paretheses

Hi, my name is Russell, and I work for a company called BUGS Bioscience.

We're a not-for-profit organisation - part tech startup, part research group - formed to make technology developed in the medical school at St Georges, University of London available globally.

We do something called "molecular serotyping", which I'll explain a bit more about shortly, and Clojure is one of the two main programming languages we currently use - and I'm going to say a bit about how we use it soon as well.

But first I wanted to say a little about who BUGS Bioscience is and where it's come from.

So as I say, we're based in St George's in Tooting, which is part of the University of London. And St George's has a few famous alumni:

John Hunter, known as the father of modern surgery whose collection - I don't know if any of you have been to the Hunterian museum? It is floor to ceiling jars of formaldehyde with all sorts of things, animal and human, in them. I'd really recommend it as an unusual day out even though I did leave it feeling a little queasy.

Then there was Edward Jenner - and BUGS Bio is based in the Jenner wing of the medical school - who was the first person to write up his findings on the use of vaccination to prevent Smallpox. It turns out he wasn't the first person to realise you could prevent disease in this way, but he was the first to write it up.

And the final alumni I want to mention - and this is someone I feel a deep personal affinity with, so I was hugely excited to find out I was working at their alma mater: comedian Harry Hill!

---

So within St Georges there has been, for a few years now, a group working on a technique for identifying strains, or more properly speaking "serotypes", of the bacteria Streptococcus pneumoniae, or Strep pneumo for short.

It can infect the lungs, causing pneumonia, it can infect the blood, causing meningitis or septicaemia, or it can cause an infection in the middle ear called otitis media, which can in the most serious cases lead to deafness.

Pneumonia is the most common symptom of pneumococcal disease, causing an estimated 1.9 million (or 19%) of the estimated 10 million child deaths each year, making it the number one vaccine-preventable cause of childhood death worldwide.

---

There are more than 90 different "serotypes" of the bacteria, and different vaccines target different serotypes - normally the most invasive serotypes common in the population - which varies by country.

So if you're planning a vaccination program, you really want to know which serotypes are most prevalent in the target population so you've got a good idea of whether your vaccine is going to work. And you want to find out which serotypes are most prevalent after you've run your vaccination program so you know what effect you've had.

But traditional serotyping is a slow, manual process, with some crucial limitations - such as that each individual technique can only detect the presence of the most abundant serotype in a sample - when in fact it will probably contain a range of different serotypes in different proportions.

And that's where these things called "micro-arrays" come in, and the technique developed by the

Bacterial
Âµ-array
Group
At
St. Georges

---

It's probably a good time to point out that I'm not a scientist, I'm a programmer, so while I'm going to describe to you how micro-arrays work, it will be a desciption filtered through the understanding of a non-scientist - not from the horse's mouth, so to speak.

So a micro-array is a slide with upwards of tens of thousands of little spots of DNA printed onto it, using what is basically a fancy inkjet printer. (Our slides have 8 x 15,000, or 120,000)

Each dot of DNA is what's called an Oligonucleotide - which just means "some nucleotides" - that matches a specific section, usually about 60 bases long, of the strep pneumo genome.

And what you do is that you take a sample (usually a nasal swab in the case of strep pneumo) and you dye it with a molecular dye that binds itself to the actual molecules of the target.

So you put the sample on the microarray and leave it in the oven overnight. (It's a special science-y oven though.) And while it's in the oven, a process called hybridization takes place: if there is DNA in the target sample that is complementary to the oligonucleotide probes, they bind together.

So the next day, all the probes that matched sections of DNA in the target are bound to that DNA, and the ones that didn't aren't. So you wash the slide to get rid of all the unattached DNA, and you shine a laser onto the slide, and if the relevant dye is present (because the sample hybridised to the probe) it fluoresces.

You take a scan of the array under the red and green laser - which looks like this - and use software to extract intensity data for each of the probes, leaving you with a dataset that looks like this.

And using some fancy Bayesian statistics developed by a team of mathematicians in Cambridge, you can use that intensity data to predict both which serotypes are present in the sample as well as their relative proportions.

---

So this, finally, is where the code comes in. But before you get too excited, I'm afraid the fancy Bayesian stuff isn't done in Clojure. Yet. At the moment, and at least for a while yet, that's all done in R.

---

So I'm going to give a quick description of our architecture so far, and talk about some of the things we've found easy and the things we've found hard.

And, actually, we're still very early on in our journey... I joined a little over six weeks ago, so so far it's been a case of starting to put skin on the bones of our walking skeleton.

So as I say the meat of the analysis is an R script. As well as this we have the user-facing part of our software, which is a compojure web-app. And rather than have the web-app call the R code directly, we've wrapped it up in a separate Clojure service that reads requests for analysis from an SQS queue. As you can imagine, there's a lot of complexity involved in the analysis, so it's been good to isolate it from the more mundane concerns of a web application.

The Compojure app exposes a JSON API, which uses Liberator, which is consumed by the Clojurescript / Reagent front-end. We use Stuart Sierra's component library to wire up all of the app's dependencies.

And in actual fact, working out the best way to use the component library was one of the first challenges we had. I have to admit to getting a bit over-enthusiastic about it, and using it for pretty much everything. And this led to a lot of boilerplate. It also leads to functions that take a LOT of arguments - which is rubbish, basically, because it obscures the useful information of what input is fundamental to that function, rather than just what its dependencies are - or even what the dependencies of the functions it calls are.

So the solution to this is to create a set of higher-level service components which contain all the dependencies you need for a given set of functions. And then you write a protocol that defines those functions and you have the service objects implement it. And this is great, because these functions don't need to take any of their dependencies as arguments, because they're all in the lexical scope of the service component.

But all those protocols, of course, just add to the boilerplate. And things are starting to remind me of years ago, when I was doing Enterprise Java....

And not only that but the functions in the service components have to be defined inline, inside the service component, for the dependencies to be in scope - which means you can't define any helper functions that need those dependencies without passing them as arguments - which puts you right back where you started.

In the end, we stripped out as much of the component stuff as we could, and kept it only for the things we explicitly needed to manage the lifecycle of: pretty much just the DB connection pool and some core.async go-loops for constantly running tasks.

---

The other big challenge has been working out how to structure a non-trivial single-page Reagent application.

I mean - Reagent is really exciting. It has been great to use. And I'm sure the same is true for Om, for those of you who use Om. The first time you realise that you just have to update the underlying data to get the page to re-render is magical.

For example, how do you implement sorting for a HTML table? Just sort the underlying data.

But it's pretty easy to end up with spaghetti code unless you have some sort of structure to adhere to. And that's what we're really still in the process of working out.

This is a short talk but I'd be really happy to discuss this with anyone who's interested in the bar later on.

---

I just wanted to very quickly list a few final things that we've found really useful - so just in case you haven't come across them, it's well worth checking them out:

* Figwheel - this watches your clojurescript files for changes and sends them to the browser without you even needing to refresh the page. It's indispensable for Clojurescript development I think.

* Dire - this - to use the Clojure terminology - "decomplects" your exception-handling, which makes the core logic of your functions much easier to read, uncluttered by try-catches.

* Tern - actually this is a plug :-). Tern is our first open source project: a migrations leiningen plugin that lets you specify your DB migrations as EDN.
